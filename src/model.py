import torch
import torch.nn as nn
import torch.nn.functional as F
import json
import os
from typing import Dict, List, Tuple, Optional

acv = nn.GELU()

def get_loss(prediction, ground_truth, base_price, mask, batch_size, alpha):
    device = prediction.device
    all_one = torch.ones(batch_size, 1, dtype=torch.float32).to(device)
    
    # ä¿å®ˆçš„å½¢çŠ¶æ£€æŸ¥å’Œä¿®å¤ï¼šåªåœ¨æ£€æµ‹åˆ°å¯èƒ½çš„å¹¿æ’­é—®é¢˜æ—¶è¿›è¡Œä¿®å¤
    original_pred_shape = prediction.shape
    original_base_shape = base_price.shape
    
    # æ£€æŸ¥æ˜¯å¦å¯èƒ½å‡ºç°å¹¿æ’­é—®é¢˜
    if prediction.ndim == 1 and len(base_price.shape) == 2 and base_price.shape[1] == 1:
        # è¿™ç§æƒ…å†µä¸‹ä¼šå‘ç”Ÿ (N,) vs (N,1) çš„å¹¿æ’­ï¼Œè½¬æ¢ä¸º (N,1) vs (N,1)
        prediction = prediction.unsqueeze(1)
        print(f"ä¿¡æ¯ï¼šæ£€æµ‹åˆ°æ½œåœ¨çš„å¹¿æ’­é—®é¢˜ï¼Œå·²ä¿®å¤é¢„æµ‹å¼ é‡å½¢çŠ¶: {original_pred_shape} -> {prediction.shape}")
    elif prediction.ndim == 2 and prediction.shape != base_price.shape:
        # å…¶ä»–å¯èƒ½çš„å½¢çŠ¶ä¸åŒ¹é…æƒ…å†µ
        if prediction.shape[0] == base_price.shape[0] and prediction.shape[1] != 1:
            print(f"è­¦å‘Šï¼šé¢„æµ‹å¼ é‡å½¢çŠ¶å¼‚å¸¸: {original_pred_shape}ï¼Œbase_priceå½¢çŠ¶: {original_base_shape}")
            prediction = prediction.squeeze().unsqueeze(1)
            print(f"å·²å°è¯•ä¿®å¤ä¸º: {prediction.shape}")
    
    return_ratio = torch.div(torch.sub(prediction, base_price), base_price)
    reg_loss = F.mse_loss(return_ratio * mask, ground_truth * mask)
    pre_pw_dif = torch.sub(
        return_ratio @ all_one.t(),
        all_one @ return_ratio.t()
    )
    gt_pw_dif = torch.sub(
        all_one @ ground_truth.t(),
        ground_truth @ all_one.t()
    )
    mask_pw = mask @ mask.t()
    rank_loss = torch.mean(
        F.relu(pre_pw_dif * gt_pw_dif * mask_pw)
    )
    loss = reg_loss + alpha * rank_loss
    return loss, reg_loss, rank_loss, return_ratio


class MixerBlock(nn.Module):
    def __init__(self, mlp_dim, hidden_dim, dropout=0.0):
        super(MixerBlock, self).__init__()
        self.mlp_dim = mlp_dim
        self.dropout = dropout

        self.dense_1 = nn.Linear(mlp_dim, hidden_dim)
        self.LN = acv
        self.dense_2 = nn.Linear(hidden_dim, mlp_dim)

    def forward(self, x):
        x = self.dense_1(x)
        x = self.LN(x)
        if self.dropout != 0.0:
            x = F.dropout(x, p=self.dropout)
        x = self.dense_2(x)
        if self.dropout != 0.0:
            x = F.dropout(x, p=self.dropout)
        return x


class Mixer2d(nn.Module):
    def __init__(self, time_steps, channels):
        super(Mixer2d, self).__init__()
        self.LN_1 = nn.LayerNorm([time_steps, channels])
        self.LN_2 = nn.LayerNorm([time_steps, channels])
        self.timeMixer = MixerBlock(time_steps, time_steps)
        self.channelMixer = MixerBlock(channels, channels)

    def forward(self, inputs):
        x = self.LN_1(inputs)
        x = x.permute(0, 2, 1)
        x = self.timeMixer(x)
        x = x.permute(0, 2, 1)

        x = self.LN_2(x + inputs)
        y = self.channelMixer(x)
        return x + y


class TriU(nn.Module):
    def __init__(self, time_step):
        super(TriU, self).__init__()
        self.time_step = time_step
        if self.time_step < 0:
            raise ValueError("time_step cannot be negative")
        
        self.triU = nn.ParameterList(
            [
                nn.Linear(i + 1, 1)
                for i in range(self.time_step)
            ]
        )

    def forward(self, inputs):
        # inputs shape: (batch, channels, time_actual) or (batch, time_actual, features)
        # TriU is designed to work on the last dimension.
        
        if self.time_step == 0:
            if inputs.ndim < 2:
                 raise ValueError("Input tensor must have at least 2 dimensions for TriU")
            output_shape = list(inputs.shape)
            output_shape[-1] = 0
            return torch.empty(output_shape, device=inputs.device, dtype=inputs.dtype)

        actual_input_time_dim = inputs.size(-1)
        effective_time_step = min(self.time_step, actual_input_time_dim)

        if effective_time_step == 0: 
            output_shape = list(inputs.shape)
            output_shape[-1] = 0
            return torch.empty(output_shape, device=inputs.device, dtype=inputs.dtype)

        current_slice = inputs[..., 0:1] 
        x = self.triU[0](current_slice) 
        
        for i in range(1, effective_time_step):
            current_slice = inputs[..., 0:i+1]
            processed_slice = self.triU[i](current_slice)
            x = torch.cat([x, processed_slice], dim=-1)
        return x


class TimeMixerBlock(nn.Module):
    def __init__(self, time_step):
        super(TimeMixerBlock, self).__init__()
        self.time_step = time_step
        self.dense_1 = TriU(time_step)
        self.LN = acv
        self.dense_2 = TriU(time_step)

    def forward(self, x):
        x = self.dense_1(x)
        x = self.LN(x)
        x = self.dense_2(x)
        return x


class MultiScaleTimeMixer(nn.Module):
    def __init__(self, initial_time_steps, channels, scales_config, 
                 activation_fn_class=nn.Hardswish, use_triu_network=True):
        super().__init__()
        self.channels = channels
        self.initial_time_steps = initial_time_steps

        self.conv_layers = nn.ModuleList()
        self.conv_scale_lns = nn.ModuleList() # LN for each convolutional scale output before concat
        
        concat_time_dim_for_triu = 0

        # Branch 1: Original scale contribution to concat_time_dim
        concat_time_dim_for_triu += initial_time_steps

        # Convolutional scales
        for scale_info in scales_config:
            if scale_info['type'] == 'conv':
                ts_after_conv = scale_info['time_steps']
                if ts_after_conv <= 0:
                    continue
                
                self.conv_layers.append(
                    nn.Conv1d(in_channels=channels, out_channels=channels,
                              kernel_size=scale_info['kernel'], stride=scale_info['stride'])
                )
                self.conv_scale_lns.append(nn.LayerNorm([ts_after_conv, channels]))
                concat_time_dim_for_triu += ts_after_conv
            elif scale_info['type'] == 'original':
                # This part of config is mainly for calculating concat_time_dim_for_triu
                # and for clarity. Original scale features are handled directly from 'inputs'.
                pass 

        if concat_time_dim_for_triu == 0:
            raise ValueError("MultiScaleTimeMixer: concat_time_dim_for_triu is 0. No valid scales.")

        if use_triu_network:
            # print("  - æ„å»ºæ—¶åºç½‘ç»œ: ä½¿ç”¨ TriU ç½‘ç»œ") # åœ¨trainè„šæœ¬ä¸­æ‰“å°ï¼Œè¿™é‡Œä¿æŒå¹²å‡€
            triu_network = nn.Sequential(
                TriU(concat_time_dim_for_triu),
                activation_fn_class(),
                TriU(concat_time_dim_for_triu)
            )
        else:
            # print("  - [æ¶ˆèå®éªŒ] æ„å»ºæ—¶åºç½‘ç»œ: ä½¿ç”¨æ ‡å‡†çº¿æ€§å±‚ (Linear) æ›¿ä»£ TriU")
            triu_network = nn.Sequential(
                nn.Linear(concat_time_dim_for_triu, concat_time_dim_for_triu),
                activation_fn_class(),
                nn.Linear(concat_time_dim_for_triu, concat_time_dim_for_triu)
            )
        
        # REMOVED: self.final_ln_before_permute (LayerNorm after concat was removed in the best version)
        self.shared_permute_and_triu = PermuteAndApplyTriUNet(triu_network)

    def forward(self, inputs):
        # inputs: (batch_size, initial_time_steps, channels)
        
        extracted_scale_features = []

        # Original scale feature (no LN before concat)
        original_scale_feat = inputs 
        extracted_scale_features.append(original_scale_feat)

        # Convolutional scale feature extraction
        conv_input = inputs.permute(0, 2, 1) # (B, C, initial_T)
        for i, conv_layer in enumerate(self.conv_layers):
            convolved_feat = conv_layer(conv_input) # (B, C, T_conv_scale)
            convolved_feat_permuted = convolved_feat.permute(0, 2, 1) # (B, T_conv_scale, C)
            
            # Apply LayerNorm specific to this convolutional scale
            normed_convolved_feat = self.conv_scale_lns[i](convolved_feat_permuted)
            extracted_scale_features.append(normed_convolved_feat)

        if not extracted_scale_features: # Should be at least original_scale_feat
            raise RuntimeError("No features extracted. Check scales_config and model setup.")
        
        concatenated_features = torch.cat(extracted_scale_features, dim=1)
        
        # Concatenated features directly go to the TriU network (via PermuteAndApplyTriUNet)
        output = self.shared_permute_and_triu(concatenated_features)
        
        return output


class StockPredict(nn.Module):
    def __init__(self, stocks, time_steps, channels, scale, activation_fn_class=nn.Hardswish, 
                 attention_num_heads=4, attention_hidden_ff_dim=None, attention_dropout_rate=0.1,
                 use_sparse_attention=True, use_multiscale_fusion=True, use_triu_network=True):
        super(StockPredict, self).__init__()
        
        # å­˜å‚¨è‚¡ç¥¨æ•°é‡å’Œæ¶ˆèå®éªŒæ ‡å¿—
        self.stocks = stocks
        self.use_sparse_attention = use_sparse_attention
        
        # --- [æ¶ˆèå®éªŒ] å¤šå°ºåº¦èåˆæ¨¡å— ---
        if not use_multiscale_fusion:
            # print("  - [æ¶ˆèå®éªŒ] å·²ç¦ç”¨å¤šå°ºåº¦æ—¶é—´èåˆï¼Œscale_factor å°†è¢«å¼ºåˆ¶è®¾ä¸º 1")
            scale = 1
        # --------------------------------

        current_scales_config_for_mixer = [] 
        calculated_concat_time_dim = 0 

        # 1. Original Scale
        current_scales_config_for_mixer.append({
            'type': 'original', 
            'time_steps': time_steps 
        })
        calculated_concat_time_dim += time_steps

        # 2. Convolutional Scales
        num_conv_scales_to_add = max(0, scale - 1)
        for i in range(num_conv_scales_to_add):
            current_stride = 2**(i + 1)
            current_kernel = 2**(i + 1)
            ts_after_conv = time_steps // current_stride
            if ts_after_conv >= 1:
                current_scales_config_for_mixer.append({
                    'type': 'conv',
                    'kernel': current_kernel,
                    'stride': current_stride,
                    'time_steps': ts_after_conv 
                })
                calculated_concat_time_dim += ts_after_conv
            else:
                break
        
        if not current_scales_config_for_mixer or calculated_concat_time_dim == 0:
            raise ValueError(
                f"StockPredict init: No valid scales generated. "
                f"Initial time_steps: {time_steps}, requested total scales: {scale}. "
                f"Resulting concat_time_dim: {calculated_concat_time_dim}. "
                "Ensure time_steps is large enough for the requested number of scales."
            )
        
        self.temporal_mixer = MultiScaleTimeMixer(
            initial_time_steps=time_steps,
            channels=channels,
            scales_config=current_scales_config_for_mixer,
            activation_fn_class=activation_fn_class,
            use_triu_network=use_triu_network # ä¼ é€’æ ‡å¿—
        )
        
        self.channel_fc = nn.Linear(channels, 1)
        self.time_fc = nn.Linear(calculated_concat_time_dim, 1)
        
        # Determine hidden_ff_dim for StockAttentionMixer if not provided
        # A common practice is to make it 4 * embed_dim, but can be tuned
        if attention_hidden_ff_dim is None:
            attention_hidden_ff_dim = calculated_concat_time_dim * 4 

        self.stock_attention_mixer = StockAttentionMixer(
            embed_dim=calculated_concat_time_dim,
            num_heads=attention_num_heads,
            hidden_ff_dim=attention_hidden_ff_dim,
            dropout_rate=attention_dropout_rate,
            activation_fn_class=activation_fn_class
        )
        
        self.time_fc_ = nn.Linear(calculated_concat_time_dim, 1)
        
        # ç¨€ç–æ³¨æ„åŠ›é…ç½®çŠ¶æ€
        self.sparse_attention_configured = False

    def setup_sparse_attention(self, dataset_name: str, ticker_list: list):
        """
        è®¾ç½®æ¨¡å‹çš„è¡Œä¸šç¨€ç–æ³¨æ„åŠ›
        
        Args:
            dataset_name: æ•°æ®é›†åç§° (SP500, NASDAQ, NYSE)
            ticker_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆæŒ‰æ•°æ®é›†é¡ºåºï¼‰
        """
        # --- [æ¶ˆèå®éªŒ] ç¨€ç–æ³¨æ„åŠ›æ¨¡å— ---
        if not self.use_sparse_attention:
            # print("  - [æ¶ˆèå®éªŒ] å·²ç¦ç”¨ç¨€ç–æ³¨æ„åŠ›ï¼Œå°†ä½¿ç”¨æ ‡å‡†å…¨è¿æ¥æ³¨æ„åŠ›")
            self.sparse_attention_configured = False # ç¡®ä¿forward passä¸­ä½¿ç”¨å…¨è¿æ¥
            return
        # --------------------------------

        print(f"ğŸ¯ ä¸ºStockPredictæ¨¡å‹è®¾ç½®è¡Œä¸šç¨€ç–æ³¨æ„åŠ›...")
        print(f"   æ•°æ®é›†: {dataset_name}")
        print(f"   ticker_listé•¿åº¦: {len(ticker_list)}")
        print(f"   æ¨¡å‹è‚¡ç¥¨æ•°é‡: {self.stocks}")
        
        # è®¾ç½®StockAttentionMixerçš„ç¨€ç–æ³¨æ„åŠ›ï¼Œä¼ é€’å®é™…è‚¡ç¥¨æ•°é‡
        self.stock_attention_mixer.setup_sparse_attention(dataset_name, ticker_list, self.stocks)
        self.sparse_attention_configured = True
        
        print(f"âœ… StockPredictæ¨¡å‹ç¨€ç–æ³¨æ„åŠ›è®¾ç½®å®Œæˆ")

    def forward(self, inputs):
        # inputs: (batch_size_is_stock_num, time_steps, channels)
        y_temporal_mixed = self.temporal_mixer(inputs)
        # y_temporal_mixed: (stock_num, calculated_concat_time_dim, channels)
        
        y_channel_processed = self.channel_fc(y_temporal_mixed).squeeze(-1)
        # y_channel_processed: (stock_num, calculated_concat_time_dim)
        
        y_out = self.time_fc(y_channel_processed)
        # y_out: (stock_num, 1)
        
        z_stock_mixed = self.stock_attention_mixer(y_channel_processed)
        # z_stock_mixed: (stock_num, calculated_concat_time_dim)
        
        z_out = self.time_fc_(z_stock_mixed)
        # z_out: (stock_num, 1)
        
        return y_out + z_out


class PermuteForConv1d(nn.Module):
    """Permutes a (batch, time, channel) tensor to (batch, channel, time)."""
    def forward(self, x):
        return x.permute(0, 2, 1)


class PermuteFromConv1d(nn.Module):
    """Permutes a (batch, channel, time) tensor back to (batch, time, channel)."""
    def forward(self, x):
        return x.permute(0, 2, 1)


class PermuteAndApplyTriUNet(nn.Module):
    """Permutes to (B, C, T), applies a TriU-based net, and permutes back to (B, T, C)."""
    def __init__(self, triu_net_module):
        super().__init__()
        self.triu_net_module = triu_net_module

    def forward(self, x):
        # x is expected as (Batch, Time, Channels)
        # TriU (and triu_net_module) expects (Batch, Channels, Time_to_process)
        x_permuted = x.permute(0, 2, 1)  # (B, C, T)
        processed_x = self.triu_net_module(x_permuted)  # Output (B, C, T_processed)
        return processed_x.permute(0, 2, 1)  # (B, T_processed, C)


class IndustrySparseAttention(nn.Module):
    """
    åŸºäºè¡Œä¸šåˆ†ç±»çš„ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶
    
    æ ¸å¿ƒæ€æƒ³ï¼š
    - åªè®¡ç®—åŒè¡Œä¸šè‚¡ç¥¨ä¹‹é—´çš„æ³¨æ„åŠ›æƒé‡
    - è·¨è¡Œä¸šè‚¡ç¥¨çš„æ³¨æ„åŠ›æƒé‡è®¾ä¸º0
    - å¤§å¹…é™ä½è®¡ç®—å¤æ‚åº¦ï¼šä»O(nÂ²)é™ä¸ºO(kÂ²Ã—m)ï¼Œå…¶ä¸­k=å¹³å‡æ¯è¡Œä¸šè‚¡ç¥¨æ•°ï¼Œm=è¡Œä¸šæ•°
    """
    
    def __init__(self, embed_dim: int, num_heads: int, dropout: float = 0.1):
        super().__init__()
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        self.dropout = dropout
        self.head_dim = embed_dim // num_heads
        
        assert self.head_dim * num_heads == embed_dim, "embed_dim å¿…é¡»èƒ½è¢« num_heads æ•´é™¤"
        
        # æ ‡å‡†çš„æ³¨æ„åŠ›æŠ•å½±å±‚
        self.q_proj = nn.Linear(embed_dim, embed_dim)
        self.k_proj = nn.Linear(embed_dim, embed_dim)
        self.v_proj = nn.Linear(embed_dim, embed_dim)
        self.out_proj = nn.Linear(embed_dim, embed_dim)
        
        # Dropoutå±‚
        self.attn_dropout = nn.Dropout(dropout)
        self.resid_dropout = nn.Dropout(dropout)
        
        # å­˜å‚¨è¡Œä¸šæ©ç çŸ©é˜µ
        self.register_buffer('industry_mask', None)
        self.industry_mapping = None
        
    def create_industry_mask(self, industry_mapping: Dict[str, str], ticker_list: List[str]) -> torch.Tensor:
        """
        æ ¹æ®è¡Œä¸šæ˜ å°„åˆ›å»ºç¨€ç–æ³¨æ„åŠ›æ©ç çŸ©é˜µ
        
        Args:
            industry_mapping: {ticker: sic_description} æ˜ å°„
            ticker_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            
        Returns:
            æ©ç çŸ©é˜µ [num_stocks, num_stocks]ï¼ŒåŒè¡Œä¸šä¸º1ï¼Œè·¨è¡Œä¸šä¸º0
        """
        num_stocks = len(ticker_list)
        mask = torch.zeros(num_stocks, num_stocks, dtype=torch.bool)
        
        # åˆ›å»ºtickeråˆ°ç´¢å¼•çš„æ˜ å°„
        ticker_to_idx = {ticker: idx for idx, ticker in enumerate(ticker_list)}
        
        # æŒ‰è¡Œä¸šåˆ†ç»„
        industry_groups = {}
        missing_industry_count = 0
        
        for ticker in ticker_list:
            if ticker in industry_mapping:
                industry = industry_mapping[ticker]
                if industry not in industry_groups:
                    industry_groups[industry] = []
                industry_groups[industry].append(ticker_to_idx[ticker])
            else:
                # å¯¹äºç¼ºå¤±è¡Œä¸šä¿¡æ¯çš„è‚¡ç¥¨ï¼Œåˆ›å»ºç‹¬ç«‹çš„"æœªçŸ¥è¡Œä¸š"ç»„
                unknown_industry = f"UNKNOWN_INDUSTRY_{missing_industry_count}"
                industry_groups[unknown_industry] = [ticker_to_idx[ticker]]
                missing_industry_count += 1
                
        print(f"ğŸ“Š æ©ç åˆ›å»ºç»Ÿè®¡:")
        print(f"   æ€»è‚¡ç¥¨æ•°: {num_stocks}")
        print(f"   æœ‰è¡Œä¸šä¿¡æ¯: {num_stocks - missing_industry_count}")
        print(f"   ç¼ºå¤±è¡Œä¸šä¿¡æ¯: {missing_industry_count}")
        print(f"   è¡Œä¸šç»„æ•°: {len(industry_groups)}")
        
        # ä¸ºæ¯ä¸ªè¡Œä¸šå†…çš„è‚¡ç¥¨è®¾ç½®æ©ç 
        for industry, indices in industry_groups.items():
            for i in indices:
                for j in indices:
                    mask[i, j] = True
        
        return mask
    
    def load_industry_data(self, dataset_name: str) -> Dict[str, str]:
        """
        åŠ è½½æŒ‡å®šæ•°æ®é›†çš„è¡Œä¸šæ•°æ®
        
        Args:
            dataset_name: æ•°æ®é›†åç§° (SP500, NASDAQ, NYSE)
            
        Returns:
            {ticker: sic_description} æ˜ å°„å­—å…¸
        """
        json_path = f'../dataset/{dataset_name}/{dataset_name.lower()}_industry_data.json'
        
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            industry_mapping = {}
            for ticker, info in data.items():
                if 'error' not in info and 'sic_description' in info:
                    industry_mapping[ticker] = info['sic_description']
                    
            print(f"âœ… æˆåŠŸåŠ è½½ {dataset_name} è¡Œä¸šæ•°æ®: {len(industry_mapping)} åªè‚¡ç¥¨")
            return industry_mapping
            
        except FileNotFoundError:
            print(f"âŒ æœªæ‰¾åˆ°æ–‡ä»¶: {json_path}")
            return {}
        except Exception as e:
            print(f"âŒ åŠ è½½è¡Œä¸šæ•°æ®å¤±è´¥: {e}")
            return {}
    
    def setup_sparse_attention(self, dataset_name: str, ticker_list: List[str], actual_stock_num: int):
        """
        è®¾ç½®ç¨€ç–æ³¨æ„åŠ›æ©ç 
        
        Args:
            dataset_name: æ•°æ®é›†åç§°
            ticker_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆæŒ‰æ•°æ®é›†é¡ºåºï¼‰
            actual_stock_num: å®é™…çš„è‚¡ç¥¨æ•°é‡ï¼ˆä»æ¨¡å‹è·å–ï¼‰
        """
        print(f"ğŸ¯ è®¾ç½®ç¨€ç–æ³¨æ„åŠ›æ©ç ...")
        print(f"   ticker_listé•¿åº¦: {len(ticker_list)}")
        print(f"   æ¨¡å‹è‚¡ç¥¨æ•°é‡: {actual_stock_num}")
        
        # è°ƒæ•´ticker_listä»¥åŒ¹é…å®é™…è‚¡ç¥¨æ•°é‡
        if len(ticker_list) != actual_stock_num:
            if len(ticker_list) < actual_stock_num:
                # å¦‚æœticker_listè¾ƒçŸ­ï¼Œç”¨å ä½ç¬¦å¡«å……
                diff = actual_stock_num - len(ticker_list)
                ticker_list = ticker_list + [f"PLACEHOLDER_{i}" for i in range(diff)]
                print(f"âœ… å·²ç”¨{diff}ä¸ªå ä½ç¬¦æ‰©å±•ticker_liståˆ°{len(ticker_list)}")
            else:
                # å¦‚æœticker_listè¾ƒé•¿ï¼Œæˆªæ–­
                ticker_list = ticker_list[:actual_stock_num]
                print(f"âœ… å·²æˆªæ–­ticker_liståˆ°{len(ticker_list)}")
        
        # åŠ è½½è¡Œä¸šæ˜ å°„
        self.industry_mapping = self.load_industry_data(dataset_name)
        
        if not self.industry_mapping:
            print("âš ï¸ è­¦å‘Š: æœªèƒ½åŠ è½½è¡Œä¸šæ•°æ®ï¼Œå°†ä½¿ç”¨å…¨è¿æ¥æ³¨æ„åŠ›")
            # åˆ›å»ºå…¨è¿æ¥æ©ç 
            self.industry_mask = torch.ones(actual_stock_num, actual_stock_num, dtype=torch.bool)
        else:
            # åˆ›å»ºç¨€ç–æ©ç 
            self.industry_mask = self.create_industry_mask(self.industry_mapping, ticker_list)
            
            # ç»Ÿè®¡ç¨€ç–åº¦
            total_connections = self.industry_mask.numel()
            active_connections = self.industry_mask.sum().item()
            sparsity = 1 - (active_connections / total_connections)
            
            print(f"ğŸ¯ ç¨€ç–æ³¨æ„åŠ›è®¾ç½®å®Œæˆ:")
            print(f"   æ©ç å¤§å°: {self.industry_mask.shape}")
            print(f"   æ€»è¿æ¥æ•°: {total_connections:,}")
            print(f"   æ¿€æ´»è¿æ¥æ•°: {active_connections:,}")
            print(f"   ç¨€ç–åº¦: {sparsity:.2%}")
            
            # åˆ†æè¡Œä¸šåˆ†å¸ƒ
            self._analyze_industry_distribution(ticker_list)
    
    def _analyze_industry_distribution(self, ticker_list: List[str]):
        """åˆ†æè¡Œä¸šåˆ†å¸ƒç»Ÿè®¡"""
        if not self.industry_mapping:
            return
            
        industry_counts = {}
        for ticker in ticker_list:
            if ticker in self.industry_mapping:
                industry = self.industry_mapping[ticker]
                industry_counts[industry] = industry_counts.get(industry, 0) + 1
        
        print(f"ğŸ“Š è¡Œä¸šåˆ†å¸ƒ (å‰10ä¸ª):")
        sorted_industries = sorted(industry_counts.items(), key=lambda x: x[1], reverse=True)
        for industry, count in sorted_industries[:10]:
            industry_short = industry[:50] + "..." if len(industry) > 50 else industry
            print(f"   {industry_short}: {count} åªè‚¡ç¥¨")
    
    def forward(self, x: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            x: è¾“å…¥å¼ é‡ [batch_size, seq_len, embed_dim]
            attention_mask: é¢å¤–çš„æ³¨æ„åŠ›æ©ç 
            
        Returns:
            è¾“å‡ºå¼ é‡ [batch_size, seq_len, embed_dim]
        """
        batch_size, seq_len, embed_dim = x.shape
        
        # æŠ•å½±åˆ°Q, K, V
        q = self.q_proj(x)  # [batch_size, seq_len, embed_dim]
        k = self.k_proj(x)  # [batch_size, seq_len, embed_dim]
        v = self.v_proj(x)  # [batch_size, seq_len, embed_dim]
        
        # é‡å¡‘ä¸ºå¤šå¤´å½¢å¼
        q = q.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)
        k = k.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)
        v = v.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)
        # ç°åœ¨å½¢çŠ¶: [batch_size, num_heads, seq_len, head_dim]
        
        # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°
        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)
        # å½¢çŠ¶: [batch_size, num_heads, seq_len, seq_len]
        
        # åº”ç”¨è¡Œä¸šç¨€ç–æ©ç 
        if self.industry_mask is not None:
            # ç¡®ä¿æ©ç åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
            industry_mask = self.industry_mask.to(attn_scores.device)
            
            # æ‰©å±•æ©ç ç»´åº¦ä»¥åŒ¹é…å¤šå¤´æ³¨æ„åŠ›
            industry_mask_expanded = industry_mask.unsqueeze(0).unsqueeze(0)  # [1, 1, seq_len, seq_len]
            industry_mask_expanded = industry_mask_expanded.expand(batch_size, self.num_heads, -1, -1)
            
            # å°†è·¨è¡Œä¸šçš„æ³¨æ„åŠ›åˆ†æ•°è®¾ä¸ºè´Ÿæ— ç©·
            attn_scores = attn_scores.masked_fill(~industry_mask_expanded, float('-inf'))
        
        # åº”ç”¨é¢å¤–æ©ç ï¼ˆå¦‚æœæä¾›ï¼‰
        if attention_mask is not None:
            attn_scores = attn_scores.masked_fill(~attention_mask, float('-inf'))
        
        # Softmaxå½’ä¸€åŒ–
        attn_weights = F.softmax(attn_scores, dim=-1)
        attn_weights = self.attn_dropout(attn_weights)
        
        # åº”ç”¨æ³¨æ„åŠ›æƒé‡
        out = torch.matmul(attn_weights, v)  # [batch_size, num_heads, seq_len, head_dim]
        
        # é‡å¡‘å›åŸå§‹å½¢çŠ¶
        out = out.transpose(1, 2).contiguous().view(batch_size, seq_len, embed_dim)
        
        # è¾“å‡ºæŠ•å½±
        out = self.out_proj(out)
        out = self.resid_dropout(out)
        
        return out


class StockAttentionMixer(nn.Module):
    """
    åŸºäºè¡Œä¸šç¨€ç–æ³¨æ„åŠ›çš„è‚¡ç¥¨æ··åˆå™¨
    ä½¿ç”¨Polygon APIæ”¶é›†çš„è¡Œä¸šæ•°æ®å®ç°ç¨€ç–æ³¨æ„åŠ›ï¼Œåªå…è®¸åŒè¡Œä¸šè‚¡ç¥¨ä¹‹é—´çš„æ³¨æ„åŠ›äº¤äº’
    """
    def __init__(self, embed_dim, num_heads, hidden_ff_dim, dropout_rate=0.1, activation_fn_class=nn.GELU):
        super().__init__()
        self.embed_dim = embed_dim
        self.num_heads = num_heads

        # ä½¿ç”¨è¡Œä¸šç¨€ç–æ³¨æ„åŠ›æ›¿ä»£æ ‡å‡†å¤šå¤´æ³¨æ„åŠ›
        self.sparse_attention = IndustrySparseAttention(embed_dim, num_heads, dropout_rate)
        
        # å‰é¦ˆç½‘ç»œ
        self.ffn = nn.Sequential(
            nn.Linear(embed_dim, hidden_ff_dim),
            activation_fn_class(),
            nn.Dropout(dropout_rate),
            nn.Linear(hidden_ff_dim, embed_dim),
            nn.Dropout(dropout_rate)
        )
        
        # å±‚å½’ä¸€åŒ–
        self.norm1 = nn.LayerNorm(embed_dim)
        self.norm2 = nn.LayerNorm(embed_dim)
        
        # å­˜å‚¨æ˜¯å¦å·²è®¾ç½®ç¨€ç–æ³¨æ„åŠ›
        self.sparse_attention_configured = False

    def setup_sparse_attention(self, dataset_name: str, ticker_list: list, actual_stock_num: int):
        """
        è®¾ç½®è¡Œä¸šç¨€ç–æ³¨æ„åŠ›æ©ç 
        
        Args:
            dataset_name: æ•°æ®é›†åç§° (SP500, NASDAQ, NYSE)
            ticker_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆæŒ‰æ•°æ®é›†é¡ºåºï¼‰
            actual_stock_num: å®é™…çš„è‚¡ç¥¨æ•°é‡
        """
        print(f"ğŸ¯ ä¸ºStockAttentionMixerè®¾ç½®è¡Œä¸šç¨€ç–æ³¨æ„åŠ›...")
        self.sparse_attention.setup_sparse_attention(dataset_name, ticker_list, actual_stock_num)
        self.sparse_attention_configured = True
        print(f"âœ… StockAttentionMixerç¨€ç–æ³¨æ„åŠ›è®¾ç½®å®Œæˆ")

    def forward(self, x):
        """
        å‰å‘ä¼ æ’­
        
        Args:
            x: è¾“å…¥å¼ é‡ [stock_num, embed_dim]
            
        Returns:
            è¾“å‡ºå¼ é‡ [stock_num, embed_dim]
        """
        # è°ƒæ•´è¾“å…¥å½¢çŠ¶ä»¥é€‚åº”ç¨€ç–æ³¨æ„åŠ›
        # ä» (stock_num, embed_dim) è½¬æ¢ä¸º (1, stock_num, embed_dim)
        batch_size = 1
        seq_len = x.shape[0]
        x_batched = x.unsqueeze(0)  # (1, stock_num, embed_dim)
        
        # æ®‹å·®è¿æ¥ + ç¨€ç–æ³¨æ„åŠ›
        residual = x_batched
        x_norm = self.norm1(x_batched)
        attn_output = self.sparse_attention(x_norm)  # (1, stock_num, embed_dim)
        x_res1 = residual + attn_output
        
        # æ®‹å·®è¿æ¥ + å‰é¦ˆç½‘ç»œ
        residual = x_res1
        x_norm2 = self.norm2(x_res1)
        ffn_output = self.ffn(x_norm2)  # (1, stock_num, embed_dim)
        x_res2 = residual + ffn_output
        
        # è½¬æ¢å›åŸå§‹å½¢çŠ¶ (stock_num, embed_dim)
        return x_res2.squeeze(0)

